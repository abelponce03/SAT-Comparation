# üìã SAT Benchmark Suite - Development Roadmap

## ‚úÖ Fase 1: Estructura Base (COMPLETADO)

### Infraestructura
- ‚úÖ Estructura de directorios completa
- ‚úÖ Base de datos SQLite con schema completo
- ‚úÖ Sistema de configuraci√≥n (YAML + JSON)
- ‚úÖ Requirements.txt con todas las dependencias
- ‚úÖ Logging y helpers utilities
- ‚úÖ CNF parser para extraer metadata

### Aplicaci√≥n Base
- ‚úÖ P√°gina principal con overview
- ‚úÖ Configuraci√≥n de Streamlit
- ‚úÖ Sidebar con estad√≠sticas
- ‚úÖ Sistema de temas y CSS personalizado

### P√°gina 1: Setup de Solvers
- ‚úÖ Listado de solvers registrados
- ‚úÖ Upload de archivos ZIP/TAR.GZ
- ‚úÖ Extracci√≥n autom√°tica
- ‚úÖ Auto-detecci√≥n de build system
- ‚úÖ Templates para solvers conocidos
- ‚úÖ Sistema de compilaci√≥n con logs en tiempo real
- ‚úÖ Agregar solver pre-compilado
- ‚úÖ Agregar desde directorio local

### Scripts Auxiliares
- ‚úÖ Script de inicio (start.py)
- ‚úÖ Script de migraci√≥n de datos existentes
- ‚úÖ README completo con documentaci√≥n

---

## üöß Fase 2: Gesti√≥n de Benchmarks (PR√ìXIMO)

### P√°gina 2: Manage Benchmarks
- [ ] Escanear directorio de benchmarks
- [ ] Upload individual/m√∫ltiple de CNF files
- [ ] Tabla interactiva con filtros (familia, dificultad, tama√±o)
- [ ] Vista de detalles de benchmark
- [ ] Clasificaci√≥n autom√°tica por familia
- [ ] Edici√≥n manual de metadata
- [ ] B√∫squeda y filtrado avanzado
- [ ] Exportar lista de benchmarks
- [ ] Importar desde SAT competition
- [ ] Validaci√≥n de archivos CNF
- [ ] Gesti√≥n de tags personalizados
- [ ] Estad√≠sticas de la colecci√≥n

### Backend Necesario
- [ ] `benchmark_manager.py`: Clase para gestionar benchmarks
- [ ] Funciones de b√∫squeda y filtrado eficientes
- [ ] Cache para metadata de benchmarks grandes
- [ ] Validador de integridad de archivos

---

## üöß Fase 3: Ejecuci√≥n de Experimentos (ALTA PRIORIDAD)

### P√°gina 3: Run Experiments
- [ ] Crear nuevo experimento (nombre, descripci√≥n)
- [ ] Selecci√≥n m√∫ltiple de solvers
- [ ] Selecci√≥n m√∫ltiple de benchmarks con filtros
- [ ] Configuraci√≥n: timeout, memory limit, parallel jobs
- [ ] Vista previa: X solvers √ó Y benchmarks = Z runs
- [ ] Bot√≥n de lanzamiento
- [ ] Monitoreo en tiempo real:
  - [ ] Progress bar global
  - [ ] Progress por solver
  - [ ] Tabla de √∫ltimos completados
  - [ ] Streaming de logs
  - [ ] Actualizaci√≥n autom√°tica cada 5s
- [ ] Controles: Pausar / Reanudar / Cancelar
- [ ] Estimaci√≥n de tiempo restante
- [ ] Checkpoint autom√°tico cada 100 runs

### Backend: Executor
- [ ] `executor.py`: Sistema de ejecuci√≥n paralela
  - [ ] Pool de workers con multiprocessing
  - [ ] Queue de tareas
  - [ ] Timeout management con subprocess
  - [ ] Memory monitoring con psutil
  - [ ] Signal handling (SIGTERM, SIGKILL)
  - [ ] Parsing de output del solver
  - [ ] Checkpoint y recovery
  - [ ] Error handling robusto

### Backend: Monitor
- [ ] `monitor.py`: Sistema de monitoreo
  - [ ] Estado global del experimento
  - [ ] M√©tricas por solver
  - [ ] Queue de resultados
  - [ ] Streaming de logs
  - [ ] Detecci√≥n de problemas (solver crashed, OOM, etc.)

### Parsers de Output
- [ ] Parser para MiniSat
- [ ] Parser para CaDiCaL
- [ ] Parser para Glucose
- [ ] Parser para CryptoMiniSat
- [ ] Parser gen√©rico (SAT/UNSAT b√°sico)
- [ ] Extracci√≥n de m√©tricas del solver

---

## üöß Fase 4: Visualizaci√≥n de Resultados

### P√°gina 4: View Results
- [ ] Tabla interactiva con todos los runs
- [ ] Filtros: experimento, solver, benchmark, resultado
- [ ] B√∫squeda full-text
- [ ] Ordenamiento por columna
- [ ] Paginaci√≥n para grandes datasets
- [ ] Vista de detalles de un run espec√≠fico
- [ ] Comparaci√≥n lado a lado (2 runs)
- [ ] Exportar a CSV/Excel
- [ ] Exportar filtrado
- [ ] Estad√≠sticas resumidas del experimento

### Backend
- [ ] Queries optimizadas con √≠ndices
- [ ] Cache de resultados frecuentes
- [ ] Formateo de m√©tricas para display
- [ ] Generaci√≥n de CSV/Excel

---

## üöß Fase 5: An√°lisis Estad√≠stico (ALTA PRIORIDAD)

### P√°gina 5: Statistical Analysis
- [ ] Selector de experimento
- [ ] Selector de m√©tricas a analizar

#### An√°lisis B√°sico
- [ ] Resumen por solver (solved, timeout, error)
- [ ] Tabla de PAR-2 scores
- [ ] Ranking de solvers
- [ ] Tiempo promedio por familia

#### PAR-2 Analysis
- [ ] C√°lculo de PAR-2 score
- [ ] Tabla comparativa
- [ ] Gr√°fico de barras

#### Virtual Best Solver (VBS)
- [ ] C√°lculo de VBS (mejor solver por benchmark)
- [ ] Comparaci√≥n VBS vs cada solver real
- [ ] Porcentaje de contribuci√≥n de cada solver al VBS

#### Comparaciones Pairwise
- [ ] Scatter plot Solver A vs Solver B
- [ ] Win/Loss/Tie analysis
- [ ] Speedup analysis
- [ ] Test de significancia estad√≠stica (Wilcoxon, t-test)
- [ ] Confidence intervals

#### An√°lisis por Familia
- [ ] Performance por familia de benchmarks
- [ ] Heatmap: solvers √ó familias
- [ ] Mejores solvers por familia

### Backend: statistics.py
- [ ] Funci√≥n para PAR-2
- [ ] Funci√≥n para VBS
- [ ] Tests estad√≠sticos (scipy.stats)
- [ ] Bootstrap confidence intervals
- [ ] Correlaci√≥n entre m√©tricas
- [ ] An√°lisis de outliers

---

## üöß Fase 6: Visualizaciones

### P√°gina 6: Visualizations
- [ ] Selector de experimento
- [ ] Selector de solvers a comparar
- [ ] Configuraci√≥n de plots

#### Cactus Plot
- [ ] Implementaci√≥n con Plotly
- [ ] Eje X: benchmarks resueltos (ordenados)
- [ ] Eje Y: tiempo acumulado
- [ ] L√≠nea por solver
- [ ] Exportar como PNG/SVG
- [ ] Interactividad (zoom, pan, hover)

#### Scatter Plot
- [ ] Solver A vs Solver B
- [ ] Puntos por benchmark
- [ ] L√≠nea de referencia (y=x)
- [ ] Color por resultado
- [ ] Escala log opcional
- [ ] Zoom interactivo

#### Performance Profile
- [ ] CDF de performance ratio
- [ ] Curvas por solver
- [ ] Interpretaci√≥n clara

#### Heatmap
- [ ] Solvers √ó Benchmarks
- [ ] Color seg√∫n resultado o tiempo
- [ ] Clustering opcional
- [ ] Exportable

#### Box Plots
- [ ] Distribuci√≥n de tiempos por solver
- [ ] Por familia de benchmarks

#### Histogramas
- [ ] Distribuci√≥n de m√©tricas
- [ ] Comparaci√≥n entre solvers

### Backend: plots.py
- [ ] Funci√≥n para cactus plot
- [ ] Funci√≥n para scatter plot
- [ ] Funci√≥n para performance profile
- [ ] Funci√≥n para heatmap
- [ ] Funci√≥n para box plots
- [ ] Utils para preparar datos
- [ ] Templates de estilo consistentes

---

## üöß Fase 7: Sistema de Reportes

### P√°gina 7: Reports
- [ ] Selector de experimento
- [ ] Plantillas de reporte (Standard, Extended, Custom)
- [ ] Configuraci√≥n:
  - [ ] Incluir qu√© secciones
  - [ ] Qu√© plots incluir
  - [ ] Formato (PDF, HTML, Markdown)
- [ ] Vista previa del reporte
- [ ] Generaci√≥n y descarga

#### Secciones del Reporte
- [ ] Executive Summary
- [ ] Experiment Configuration
- [ ] Solvers Description
- [ ] Benchmarks Overview
- [ ] Results Summary (tabla)
- [ ] Statistical Analysis
- [ ] Visualizations (plots embebidos)
- [ ] Conclusions

### Backend: report_generator.py
- [ ] Templates con Jinja2 o similar
- [ ] Generaci√≥n PDF con ReportLab
- [ ] Generaci√≥n HTML
- [ ] Generaci√≥n Markdown
- [ ] Embedding de plots (base64 para HTML/PDF)
- [ ] Formateo de tablas
- [ ] Sistema de secciones modulares

---

## üîß Mejoras y Features Adicionales

### Sistema
- [ ] Sistema de plugins para nuevos solvers
- [ ] API REST para automatizaci√≥n externa
- [ ] Autenticaci√≥n multi-usuario (opcional)
- [ ] Sistema de notificaciones (email cuando termina experimento)
- [ ] Backup autom√°tico de base de datos
- [ ] Importar/Exportar configuraciones completas
- [ ] Modo "dry-run" para testear configuraci√≥n

### Optimizaciones
- [ ] Cache de queries frecuentes
- [ ] Paginaci√≥n en tablas grandes
- [ ] Lazy loading de benchmarks
- [ ] Compresi√≥n de outputs de solvers
- [ ] √çndices adicionales en base de datos
- [ ] Cleanup de archivos temporales

### An√°lisis Avanzado
- [ ] Machine Learning: predecir dificultad de benchmark
- [ ] Clustering de benchmarks similares
- [ ] Feature extraction de CNF files
- [ ] Portfolio solver simulation
- [ ] An√°lisis de sensibilidad de par√°metros

### Integraci√≥n
- [ ] Import desde SAT Competition results
- [ ] Export a formato EDACC
- [ ] Compatibilidad con Slurm (HPC clusters)
- [ ] Docker containerization
- [ ] CI/CD para testing autom√°tico

---

## üìÖ Cronograma Sugerido

### Semana 1-2: Fase 2 (Benchmarks)
- Implementar gesti√≥n completa de benchmarks
- Testing con tus 400 benchmarks existentes

### Semana 3-4: Fase 3 (Experiments)
- Sistema de ejecuci√≥n paralela
- Monitoreo en tiempo real
- Testing con experimentos peque√±os

### Semana 5: Fase 4 (Results)
- Vista de resultados
- Exportaci√≥n
- Testing con datos migrados

### Semana 6-7: Fase 5 (Statistics)
- An√°lisis estad√≠stico completo
- PAR-2, VBS, comparaciones
- Validaci√≥n de m√©tricas

### Semana 8: Fase 6 (Visualizations)
- Todos los plots principales
- Interactividad y exportaci√≥n

### Semana 9: Fase 7 (Reports)
- Sistema de reportes
- Templates y generaci√≥n

### Semana 10: Testing & Polish
- Bug fixes
- Optimizaciones
- Documentaci√≥n

---

## üéØ Prioridades Inmediatas

1. **AHORA**: Migrar tus datos existentes
   ```bash
   python migrate_existing_data.py
   ```

2. **SIGUIENTE**: Implementar Fase 2 (Benchmarks)
   - Para que puedas gestionar tus 400 CNFs

3. **LUEGO**: Implementar Fase 3 (Experiments)
   - Para que puedas lanzar nuevos experimentos

4. **DESPU√âS**: An√°lisis y Visualizaciones
   - Para comparar solvers

---

## üìù Notas de Desarrollo

### Decisiones de Arquitectura
- **SQLite**: Suficiente para millones de runs, sin necesidad de server
- **Multiprocessing**: Mejor que threading para CPU-bound tasks
- **Streamlit**: R√°pido desarrollo, UI moderna, pero limitado para real-time
- **Plotly**: Gr√°ficos interactivos, mejor que matplotlib para web

### Consideraciones
- **Timeout handling**: Usar `signal` en Linux, `subprocess.communicate(timeout=...)` en Windows
- **Memory limits**: Dif√≠cil en Windows, posible con `psutil` monitoring
- **Parallel execution**: Cuidado con race conditions en DB (usar locks)
- **Large datasets**: Implementar paginaci√≥n y streaming

### Testing
- Probar con 5-10 benchmarks primero
- Validar parsers con outputs reales
- Verificar memory leaks en ejecuci√≥n larga
- Testing en Windows y Linux (diferencias en subprocess)

---

## ‚ùì Preguntas para Continuar

1. **¬øQuieres que empiece con la Fase 2 (Benchmarks) ahora?**
   - O prefieres primero probar la estructura base

2. **¬øTienes solvers adicionales que quieras agregar?**
   - Puedo configurar templates espec√≠ficos

3. **¬øQu√© an√°lisis estad√≠sticos son m√°s importantes para tu tesis?**
   - PAR-2, VBS, otros?

4. **¬øNecesitas features espec√≠ficas no mencionadas?**
   - Puedo ajustar el roadmap

---

**Siguiente paso: ¬øQu√© quieres que implemente primero?** üöÄ
